최적값 찾는것 2가지 : 최소값을 찾거나 최대값을 찾거나
cost(w, b)

절대값함수는 미분을 할 수 없으므로, 제곱을 취한다.

기울기의 반대방향으로 가면, cost가 최소가 되는 기울기값을 찾을 수 있다.

이걸 수식으로 형상화 한것이, w = w-(da/dw)*cost(w)



미니배치
경사하강법
과적합(Overfiting)

####오늘, 시작을 어디서 할까?####
일단, 랜덤으로 주고 시작을 한다.

정규분포 초기화의 문제점

시그모이드를 적용하면, 정규분포를 이용한 초기화에서는 w가 아무리 작아도, wx*b의 값이 발산한다.
w를 양수로 했기 때문에, wx*b가 발산했다고, 생각하여, w의 분포를 -4 ~ 4의 범위로 재조정(정규분포), sigmoid는 5보다 크면, 1, -5보다 작으면 0으로 추정(이것은 제대로 학습이 되지 않은것)

w의 크기를 더 줄이기 위해, 정규분포 N(0, 1)에 따르는값으로 w의 범위 지정 결과값들이 -5 ~ 5 사이이기 때문에, sigmoid함수의 분포가 고르게 된다.

요약 : 시그마 한 후 결과 값이 너무 크니까, w를 최소화 하자

w분포 : w가 0 ~ 1사이의 값

영상에서는 sigma(wx + b)로 처리해주어야할게, 몇만개 이상이다.
정규분포를 하면, sigmoid 쓰는게, step함수와 같은 효과를 준다.

 출력이 1이 된다.


################################
w를 다 양수로 해서 문제가 되는것, 그래서, -4 ~ 4로 초기화를 하게 한다.
sigmoid 5보다 크면, 다 1, -5보다 작으면, 0으로 

그래서, N(0, 0.1)
대부분이 sigmoid값에서 의미가 있는, 0과1의 사이값(경사)에 분포

그래서, 2가지 초기화 방법을 이제 사용해 보겠다.

입력노드 개수와 출력노드 개수를 토대로 결정

CNN할때는, He 초기화를 사용

오늘 익혀야 할 최적화 학습방법

가져다 쓰는건 쉬운데, 원리를 파악하자, 데이터 셋이 많아야 한다.

입력이미지 => [컨볼루션 계층 => 풀링 계층] => 다층 신경망 계층



DNN과 다른점

필터가 설계가 이미 되어있음

CNN은 그게 weight 경사하강법을 통해 그걸 우리가 결정해야한다.



만약, 3*3 필터를 10개를 사용하겠다. 9 * 10개의 파라미터를 계산하겠다.

CNN은 MaxPoling을 통해 사이즈를 줄여주어야한다.

MaxPoling : 영상 사이즈를 반으로 줄여준다. 최대값으로 선택, 필터수가 변하는게 아니다. 필터수는 고정

input 4*28*28*1, 샘플 4개가 28*28의 크기를 갖음, 1개의 필터

convolution 4*28*28*25 샘플 4개가  28*28의 크기를 갖음, 25개 필터

MaxPoling 4*14*14*25 샘플 4개가 반으로 줄어, 14 * 14의 크기를 갖음, 25개 필터

convolution 4*14*14*50 샘플 4개가 14*14의 크기를 갖고, 50개의 필터를 가짐

Maxpoling 4*7*7*50

그래서, 4*2450(2차원으로 변환)의 값이 넘어가고, 그것을 가지고 학습

w를 구하는 이유 : 영상의 크기에 의존하지 않고, 몇개의 필터를 몇*몇짜리를 쓸거냐
w = 필터수 * 필터크기

예를들어, 앞에있는 필터는 엣지나, 밝기 그런것, 중간은 눈, 코, 입, 마지막에는 얼굴을 구분할 수 있는 필터



input은.... 구글같은 큰회사부분에 맡기자.

우리는 output부분만 건드린다.
마지막층 몇개만 학습시키고, 앞층은 놔두자

윗부분 : 엣지나, 밝기 파악
중간 : 눈, 코, 입
------------------
마지막 : 얼굴

마지막 부분만, 원하는대로 가공하여, 학습을 시키자, 그렇게 되면, 적은 샘플에서도 좋은 학습률이 나온다.

그게 전이학습